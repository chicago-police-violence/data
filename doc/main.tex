\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage[capitalize]{cleveref}
\usepackage{graphicx}
\usepackage{color}
\newcommand{\tbo}{}
\title{A data repository about the activities of the Chicago Police Department}

\begin{document}


\maketitle

\begin{abstract}
	We present a new dataset focusing on the personnel and activities of the
	Chicago Police Department (CPD). The data was curated starting multiple
	data releases by the Chicago Police Department following a series of
	requests under the the Freedom of Information Act. In this document we give
	a detailed description of the content of the dataset as well as the data
	cleaning process.
\end{abstract}

\section{Introduction}

The original data was obtained following a series of requests covered by the
Freedom of Information Act (FOIA) to the Chicago Police Department (CPD) and
the Civilian Office of Police Accountability (COPA). The information which was
requested pertained to CPD's personnel and its activities.

\textbf{TODO:} ideally say a bit more about the history of these FOIA requests.
Apparently they were initiated by individual journalists and lawyers and were
later coordinated by the Invisible Institute which ultimately became the
central location were (almost) all the data is currently available.

\begin{table}[h]
	\begin{center}
\begin{tabular}{@{}llll@{}}
	\toprule
	request \#&received&requested&description\\
\midrule
	\texttt{P0-58155}&2017-04-17& &Officer roster\\
	\texttt{P4-41436}&2018-03-21& &Officer roster\\
		\texttt{P0-52262}&2016-12-04&2016-09-19&Unit assignment\\
		\texttt{16-1105}&2016-03-11&2016-02-10&Unit assignment\\
	\texttt{P0-46957}&2016-06-29&2016-04-22&Complaints (CPD)\\
	\texttt{18-060-425}&2018-08-28&2018-08-20&Complaints (COPA)\\
	\texttt{P0-46360}& & &Tactical Response Reports\\
\bottomrule
\end{tabular}
\caption{Summary of the FOIA requests to the CPD and COPA contained in our repository.}
\label{table:summary}
\end{center}
\end{table}

Each FOIA request is identified by a request number, \cref{table:summary} gives
an overview of all the requests made to the CPD and COPA that are present in
our repository. This information is also available in the file
\texttt{dataset.csv} in the root folder of the repository. The original
data—that is the files received after each FOIA request—are present in the
\texttt{raw/} folder of the repository, with one subfolder for each request,
identified by the request number. When available, each subfolder also contains
the formal request letter as well as the reply letter from the CPD or COPA,
which are useful in understanding what data was included in each dataset.
Some additional comments about the data:
\begin{itemize}
	\item \emph{Officer roster:} lists all officers (past or present) employed
		by the CPD along with attributes such as year of birth, age, race,
		gender, appointment date, resignation date, etc.
	\item \emph{Unit assignment:} the CPD is organized into (500 or so?) units.
		Each officer can be assigned to one or multiple units and these
		assignments can change over time. The unit assignment datasets contain
		one record for each officer and each unit they were assigned to, with
		the start date and end date of this assignment.
	\item \emph{Complaints:} formal complaints filed by citizens against police
		officers. Complaints are identified by a complaint number, and there is
		one record for each complaint and each officer listed on the complaint,
		indicating the allegation made against them, result of the
		investigation of the allegation (with possible sanction), etc.
	\item \emph{Tactical Response Reports:} these are forms that officers are
		required to file after each incident for which the officer's response
		involved use of force.
\end{itemize}

Let us already mention an inherent difficulty in making use of this data, which
will be discussed in \cref{sec:linking}: there is no number/identifier which
uniquely identifies officers across datasets. Such an identifier probably
exists internally in the CPD, but was never included in the data released to
the public. One would be tempted to believe that the \emph{badge number} (also
sometimes referred to as \emph{star number} of an officer is such an
identifier, but unfortunately, it changes over the course of an officer's
career in the CPD, and a given badge number can be reassigned to different
officers when they are no longer in use.

\paragraph{Technical choices.} Code is written in Python, use of \texttt{Make}
to coordinate the various processing steps and easily reproduce them.
\textbf{TODO:} say a bit more about the requirements of the environment, or
maybe simply refer to the README?

\section{Initial Cleaning}

The files initially released by the CPD as a reply to the FOIA requests are for
the most part Excel spreadsheets, with inconsistent formatting and which can
thus be difficult to process programmatically. As an example, the reader is
invited to open the file
\texttt{p046957\_-\_report\_1.1\_-\_all\_complaints\_in\_time\_frame.xls}
available in the folder \texttt{raw/P0-46957/}. As can be seen, each record in
this file is spread over two rows of the spreadsheet, with the field names
repeated at the beginning of the second row for each record.

The goal of the cleaning step is thus to produce ``reasonable'' CSV files from
the original files, with the minimum requirement that each record be presented
on a single line after this step. The code for this cleaning step is contained
in the files \texttt{datasets.py}, \texttt{parse.py} and
\texttt{parse\_p046957.py} in the \texttt{src/} folder and the entire step can
be applied by running \texttt{make parse} in the root of the repository. This
creates the folder \texttt{parsed/} containing the clean CSV files.

As can be seen by inspecting the code, the decisions made at this stage are, we
believe, uncontroversial as they only consists of:
\begin{itemize}
	\item unifying field names across datasets, so that the same type of data
		is always identified in the saw way (for example, \texttt{Appointment
		Date}, \texttt{Appt Date}, \texttt{appointment\_date} are all mapped to
		\texttt{appointment\_date}.
	\item unifying field values across datasets. For example, the gender of an
		officer is indicated as a single letter \texttt{M} or \texttt{F} in
		some datasets or as \texttt{Male}, \texttt{Female} (based on the data
		release, it does not seem that the system used by the CPD has an option
		to represent non-binary officers).
	\item parsing values into the correct data type or format. For example,
		dates are formatted differently depending on the dataset, and we map
		everything to the ISO 8601 format.
\end{itemize}

Consequently, for someone planning to use the data in the present repository,
there is virtually no reason not to start at the minimum from the output of
this cleaning step. The subsequent steps required making more difficult and
debatable decisions, so depending on the application, researchers might want to
perform them differently, but in all cases, those alternative decisions can
branch off from the output of the cleaning step.

\section{Linking and Merging Datasets}\label{sec:linking}

\subsection{Officer matching}

As already alluded to, the main challenge at this step is that there is no
identifier uniquely identifying officers across records. In other words, there
is no foolproof way to know if two different records correspond to the same
officer, \emph{even within the same dataset} (for example the same officer
could appear with slightly different attributes on two different complaint
records).

We thus need to design a matching method striking a balance between
\begin{itemize}
	\item being loose enough to avoid type II error (false negatives). If the
		same officer appears with slightly different attributes across two
		records, we do not want our matching method to believe it is two
		different officers.
	\item being strict enough to avoid type I error (false positives). We do
		not want to merge two different officers into a single identity.
\end{itemize}

The difficulty in achieving this balance is that perhaps surprisingly
\emph{none of the attributes of a given police officer are guaranteed to be
stable over time}. Most notably, officers' names change over time, for example
to fix data entry errors or in case of legal name changes. However, we observed
two attributes, present in almost all original datasets and which seem
remarkably stable over the time: \emph{appointment date} and \emph{birthyear}.
These two attributes thus proved very valuable to disambiguate officers with
identical names.

In order to match officers across two datasets, we developed an \emph{iterative
pairwise matching procedure} that makes iterative passes over the datasets.
During each pass, a subset of the officer attributes present in both datasets
is selected as the matching criterion, and a pair of officers (one from each
dataset) is identified as a \emph{match} if (i) their attributes from the
chosen subset match, and (ii) if they are the only two officers matching on
these attributes. Once a pair is identified as a match, it is put aside, and
the next pass is performed on the remaining unmatched officers. After all the
passes are done the leftover officers are declared as different officers. By
constructing a hash table mapping a subset of attributes to the list of
officers sharing these attributes, each pass can be performed in linear time,
so the overall running time of the procedure is $O\big(P(N_1+N_2)\big)$ where
$P$ is the number of passes and $N_1, N_2$ are the number of officers in each
dataset.

To fully specify the matching procedure we thus need to specify which subset of
attributes is chosen as the matching criterion at each pass. For this, we go
from the stricter to the looser criterion: for the first pass, we choose
a subset \emph{all} the attributes which are present in two datasets, and then
start removing attributes one by one. For example, one can remove the
\emph{last name} attribute for the second pass to match a pair of officers
whose last names are different but match on all the remaining attributes, thus
identifying an officer whose last name changed between the releases of the two
datasets. The advantage of going from stricter to looser is two fold:
\begin{itemize}
	\item starting from the strictest set of attributes identifies the
		\emph{unambiguously matching pairs}, that is, the ones which are
		a clear match and which, thankfully, constitute the vast majority of
		officers (typically around 80-90\% of officers are matched during the
		first pass \textbf{TODO check}). Since the next passes will only be
		performed on the remaining unmatched officers, this removes a lot of
		potential ambiguities which could occur once the set of attributes is
		reduced.
	\item since the vast majority of officers is matched during the first pass,
		it becomes feasible during the subsequent passes to visually inspect all
		the matched pairs and assess whether the chosen set of attributes was
		too strict or too lose (\textbf{TODO:} explain how to activate
		debugging information in the code).
\end{itemize}

We note that there is still some amount of subjective judgment involved,
following a visual inspection of the second and subsequent passes, to decide
which sets attributes are ``acceptable'' (that is, for which the probability of
two persons sharing these attributes in a population of the size of the CPD is
extremely small). This is also how we decide that sufficiently many passes have
been performed: when it would seem likely to introduce a type I error by
matching any of the remaining officers. As a general rule of thumb we erred on
the side of favoring type II errors over type I errors. That is, we only
matched officers when it would seem extremely unlikely that they correspond to
two different individuals).

\textbf{TODO:} table of officer attributes in each dataset

\textbf{TODO:} explain the few subtleties where we don't use equality to match
attributes (for example when matching age and birthyear, where the age only
lets us identify the birthyear with an accuracy of 1 year). Or with stars,
where we test whether a star number is contained in the subset of known stars
for this officer.

With this procedure at hand we can thus link officers across datasets starting
from the most similar datasets first (for which we expect to have the least
amount of ambiguity). That is we first link \texttt{P0-58155} to
\texttt{P4-41436}, then \texttt{P0-52262} to \texttt{16-1105} and then the
remaining datasets \textbf{expand}

\textbf{TODO} give in appendix table summarizing which subset of attributes are
used at each linking operation 

\subsection{Roster consolidation}

A byproduct of matching officers across datasets is that for each officer, we
now have as many “profiles” as the number of datasets in which they appear,
where by \emph{profile} we mean a collection of attributes. Note that each
profile can contain a different subset of attributes (since not all attributes
are present in each dataset) and that a given attribute might take a different
value in different profiles of the same officer (since the iterative matching
procedure is not restricted to performing strict matching).

We are thus faced with the task of “consolidating” the different profiles of
a given officer into a single profile. Of course, if an attribute is present in
a single profile, and absent from the others, this is the value we keep in the
consolidated profile. But if an attribute appears with different values across
different profiles, we choose the value coming from the profile corresponding
to the \emph{most recent data release}.

\subsection{Unit assignment history} TODO.


\input{sections/data.tex}

\section{Intended Use}

Benchmark algorithms for:
\begin{itemize}
	\item community detection (where for example unit assignment can be used to
		have a ground truth
	\item network inference from contagion data (complaint network can be used
		as ground truth, shootings as the contagion)
	\item time series prediction over networks
\end{itemize}

Relatedly, useful to assess and design contagion models


\textbf{TODO:} the following was copy-pasted from Daria's email.

In my view, in discussing intended uses for the data set, we should probably focus attention at the outset on the benchmarking capacities for our data:

\begin{itemize}
	\item Algorithms to detect network spatial and temporal clustering
	\item Algorithms to fit models of contagion on the network (in addition to shooting generally, researchers can examine other behaviors independently documented, like foot-chase shootings, use of force during arrest, abusive charging behavior, but also laudatory behavior like complying with reporting requirements, etc.)
\end{itemize}

Other uses for this dataset can include:

\begin{itemize}
	\item Correlating police behavior to police traits and complainant traits (like race, gender, location of assignment/residence, years on force, etc.)
	\item Correlating complaint filing frequency to police traits and complainant traits (see above)
	\item Creating network graphs for subunits of interest (particular police patrol districts, for example).
	\item Tracking complaint trends relative to external events like new disciplinary practices, new training techniques, new oversight (Department of Justice, police union monitoring, new civilian oversight, publication of shootings in major papers) and other events like high-profile scandals, introduction of new technologies like Tasers, etc.
	\item Subject to caveats, investigating how to control for the dangerousness of police work when investigating the frequency of particular police behaviors (use of excessive force, wrongful arrest, abusive speech, etc.)
\end{itemize}

\end{document}
