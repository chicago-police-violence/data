\section{The CPD Data} \label{sec:data}

The original raw data released by the CPD, as well as the code to generate both
the cleaned data and this document, are available in a GitHub repository at
\url{https://github.com/chicago-police-violence/data}. This repository will
serve as a long-term home for this data, its current and future releases, as
well as discussions regarding improvements and extensions of the data
processing code. Refer to \texttt{README.md} in the repository for details
regarding system requirements and how to run the data processing code. 

\subsection{The raw data: origin, description, and challenges}
\label{sec:raw}

\paragraph{Origin.}
The first raw data files in this repository were obtained by J.~Kalven, an 
independent journalist, who filed Illinois Freedom of Information Act (FOIA) requests with 
the Chicago Police Department regarding complaints filed against officers. 
In Kalven v.~City of Chicago \cite{kalven2014}, an Illinois appellate court issued
a general ruling that documents bearing on allegations of
police abuse are public information. Following 
the decision, the non-profit
Invisible Institute began to collaborate with Kalven 
and the University of Chicago's Mandel Legal Aid
Clinic to follow up on earlier FOIA requests and to file new ones. The data
disclosed in response to these earlier and now ongoing FOIA requests were made available
online as part of the Citizens Police Data Project \cite{cpdp}.
These data form the basis of the cleaned and linked data set provided by the present work.

\begin{table}[h]
	\begin{center}
\caption{Summary of the FOIA requests contained in our repository (blanks are missing entries).}
\vspace{0.5em}
\label{table:summary}
\begin{tabular}{@{}llllr@{}}
	\toprule
	Request \#&Received&Requested&Description& \# Records\\
\midrule
	\texttt{P0-58155}&2017-04-17& &Officer roster& 32\,446\\
	\texttt{P4-41436}&2018-03-21& &Officer roster& 14\,634\\
	\texttt{16-1105}&2016-03-11&2016-02-10&Unit assignments&114\,630\\
	\texttt{P0-52262}&2016-12-04&2016-09-19&Unit assignments&115\,987\\
	\texttt{P0-46957}&2016-06-29&2016-04-22&Complaints (CPD)&109\,339\\
	\texttt{18-060-425}&2018-08-28&2018-08-20&Complaints (COPA)&182\,337\\
	\texttt{P0-46360}& & &Tactical Response Reports&67\,019\\
	\texttt{P0-46987}&2016-05-13&2016-04-25&Unit names&237\\
	\texttt{P0-61715}& &2017-07-26&Awards&699\,912\\
	\texttt{P5-06887}&2019-10-11&2019-07-19&Awards&60\,556\\
					 &2017-09-27&2017-09-13&Salary&212\,508\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\paragraph{Description.}
The raw data files are contained in the \texttt{raw/} folder of the repository.
Each subfolder corresponds to a FOIA request, which is generally identified by
a request number. \cref{table:summary} gives an overview of all the requests
that we include in our repository; this meta-information is also included in
the \texttt{raw/datasets.csv} file in the repository. The subfolders contain
the data provided by the city in response to their corresponding FOIA requests,
which typically comprises multiple Excel spreadsheets. In addition, when
available, the subfolders contain formal correspondence regarding the request,
which often provides useful contextual information in understanding the data.  

In particular, the raw data files contained in the repository
provide the following information:
\begin{description}
	\item[Officer roster:] a list of all officers (past and present) employed
		by the CPD along with attributes such as year of birth, age, race,
		gender, appointment date, resignation date, etc.
	\item[Unit assignments:] the CPD is organized into over 200 units.
		Each officer can be assigned to one or multiple units and these
		assignments can change over time. The unit assignment datasets contain
		one record for each officer and each unit they were assigned to, including
		the start date and end date of this assignment.
	\item[Complaints:] formal complaints against police officers, filed both by
		citizens and internally within the department. Complaints are
		identified by a complaint number. There is one record for each
		complaint and each officer listed on the complaint, indicating the
		allegation made against them, result of the investigation of the
		allegation (with possible sanction), etc.
	\item[Tactical Response Reports:] these are forms that officers are
		required to file after each incident for which the officer's response
		involved use of force. There is one record for each incident and each
		officer involved in the incident. Each record contains details about
		the incident (such as time and location), the officer involved and the
		subject of the use of force. In case one or multiple weapons were used,
		detailed information about each use is also provided including, for
		firearms, the number of discharges and the object struck at each
		discharge.
	\item[Unit names:] the (human-readable) name of each past and present
		unit in the CPD. These names provide information about the function of
		each unit and also appear occasionally where unit numbers are listed in
		the other data files.
	\item[Awards:] a list of all awards requested for officers in the CPD,
		including award tracking number, reference number, award type, request
		date, requester name, etc.
	\item[Salary:] a list of officers including their salary, position, and pay grade.
\end{description}

\paragraph{Challenges.}
Despite the richness of the information contained in these FOIA data releases,
there is a major obstacle to using them for investigating the activities of the
CPD. In particular, police officers are not uniquely identified across datasets; there is
a priori no reliable way to know whether, for example, an officer listed on
a Complaint is the same individual as an officer with similar attributes listed
on a Tactical Response Report. Therefore, one is forced to link officers
across datasets using a restricted set of attributes, 
which introduces the following challenges:
\begin{itemize}
	\item \emph{Time-varying attributes:} many attributes change over the
		course of an officer's career in the CPD, such as their unit
		assignments, rank, and badge number (referred to as a ``star'' in the data). 
                Perhaps surprisingly, some
		attributes which would usually be considered stable and useful
		identifiers also change over time. For example, surnames change when
		officers marry, and appointment dates change when database entries are
		corrected internally.
	\item \emph{Multiple internal sources:} the salary data comes from
		a different database. In particular, the officers' names were entered
		separately, which makes linking this data to the other datasets
		particularly challenging.\footnote{Is this the only case in which data from different DB? If so, we could move this bullet point lower down as the other challenges seem ``worse''}
	\item \emph{Inconsistent entries:} various choices were made by the CPD to
		decide which officers to include in each dataset.  There are, for
		example, officers missing from the roster or unit assignment data, but
		present in the salary data. Furthermore, the same attribute can appear
		under different names in different datasets and sometimes have
		ambiguous meanings: for example, the salary data contains two different
		attributes for the appointment date. Fields that are available or missing
		per record also vary across databases.
	\item \emph{Duplicate entries:} probably due to internal errors in the CPD
		data infrastructure, some officers are sometimes duplicated in the
		roster and unit assignment data: they appear twice in the same dataset,
		as two different individuals but with the exact same attributes. One of
		the two “copies” of each duplicate officer is inactive and never
		appears in the rest of the data, but introduces ambiguities to uniquely
		identify officers across datasets.
	\item \emph{Systematic errors:} an unusual difficulty arose from the unit
		assignment data, in which a significant fraction of the assignments
		have an end date chronologically preceding the start date. This appears
		to be a systematic error, either in the data entry process or in the
		code which produced the data. A close inspection of the pattern of
		errors revealed that the faulty records cannot be fixed by simply
		swapping the start date with the end date.
\end{itemize}


\subsection{Data Cleaning and Linking}\label{sec:cleaning}

A major contribution of the present work is to address all the above challenges
by carefully cleaning and linking the original datasets. The output of this
process is a collection of comma-separated values (CSV) files corresponding to
the different entities in the \emph{Description} paragraph above.  Importantly,
each officer is uniquely identified by a hexadecimal string across output
files. To produce the final, cleaned dataset, run \texttt{make} in the root of
the repository. The output files will be found in the \texttt{final/} folder;
please refer to \texttt{description.md} for a description of the content of
each these files. We now give an overview of each processing steps, more
details can be found in \cref{sec:app-cleaning}.

\paragraph{Initial Cleaning.} In the first step, we produce uniformly formatted
CSV files from the raw Excel spreadsheets. The decisions made at this stage are
sraightforward and involve no subjective judgement since they consist of (1)
unifying attribute names and values across datasets, (2) parsing integers and
dates into a standard format, and (3) concatenating records of the same type
when they were split over multple spreadsheets.

Since it can be useful in some applications to work directly from these
files—for example, when the linking step described next needs to be performed
differently—it is possible to perform only this initial cleaning step by
running \texttt{make prepare} in the root of the repository. The files output
at this step will be found in the \texttt{tidy/} folder.

\paragraph{Linking and merging datasets.}
Next, we address the challenge of uniquely identifying officers across datasets.
At a high level, our procedure \emph{grows} a population of uniquely identified
officers by sequentially examining each FOIA release. Each unique officer in
this population is assigned a unique identification (UID), which is a random hexadecimal string (e.g.\
\texttt{9bc51eef-c37b-4eff-a14d-7e69f56b3d1e}), and to each UID is associated
a list of \emph{officer profiles}. There is one \emph{officer profile} for each
unique officer and each FOIA release in which this officer appeared, listing
the identifying attributes of this officer as they appear in this given data
release. In detail, for each FOIA release:
\begin{enumerate}
	\item We build a list of all the \emph{officer profiles} appearing in this
		release.
	\item For each officer profile, we attempt to \emph{match} it against the
		profiles of the population of unique officers constructed so far from
		previously examined FOIA releases.
		\begin{itemize}
			\item If the match is successful, we have identified a unique officer in
				the population whose profiles unambiguously match with the
				current profile. In this case, we simply attach the current
				profile to this officer and UID, and
				the population does not grow.
			\item If the match is unsuccessful, we add a new officer with a new UID to the population of unique
				officers and attach the current profile to this new officer.
		\end{itemize}
\end{enumerate}

The \emph{match} operation in step 2.\ is achieved by an iterative pairwise
procedure that we developed and whose details are given  in \cref{sec:linking}.
After all FOIA releases have been processed, the population contains the set of
all unique officers appearing in the original data. Each officer is represented
by UID and a collection of profiles, representing the various ways in which
this unique officer appears across different datasets. These profiles can be
found in the file \texttt{final/officer\_profiles.csv}.
At this point the \texttt{final/} folder also contains
one file for each type of record (complaints, tactical response reports, etc).
Within these files, officers are identified solely by their UID and other attributes
are removed; this avoids duplication of
information since these attributes are redundant with those found in
\texttt{final/officer\_profiles.csv}.

\paragraph{Final steps.} For convenience, we consolidated the
different profiles of each officer into a single, canonical profile as follows.
For each officer's identifying attribute, we choose the \emph{most recent
nonempty} value it takes among all profiles of this officer, where \emph{most
recent} is defined using the release date of each dataset by the CPD. In this way,
if an attribute is empty in some profiles but present in others, a nonempty value
will be selected. Choosing the most recent value is justified since (1) it is
more likely to still be current (2) it is more likely to contain the latest
corrections made by the CPD to their database. The consolidated profiles
for each unique officer can be found in the file \texttt{data/roster.csv}.

As already alluded to in \cref{sec:raw}, the unit assignment data revealed that
around 6\% of the records display an end date chronologically preceding the
start date of the assignment. A closer inspection of these faulty records
revealed a systematic pattern: whenever such a record appears, it is possible
to find among the other assignments of the same officer another record whose
start date is exactly one day after the end date of the faulty record. This led
us to formulate the following hypothesis: \emph{the faulty end dates where not
manually entered, but were instead automatically generated by the data
infrastructure of the CPD}.  More specifically, we believe the end dates were
added by a piece of computer code which processed all unit assignments in
order, and set as the end date of each assignment, the day immediately
preceding the start date of the following assignment. The faulty records then
arose from the fact that they were wrongly positioned in the order considered
by the computer code. We used this hypothesis as the basis for the cleaning of the unit assignment data, whose details are given in \cref{sec:final-cleaning}.

