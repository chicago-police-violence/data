\section{The CPD Data} \label{sec:data}

The original raw data released by the CPD, as well as the code to generate both the
cleaned data and this document, are available in a GitHub
repository at \url{https://github.com/chicago-police-violence/data}. This
repository will serve as a long-term home for this data, its current and future
releases, as well as discussions regarding improvements and extensions of the
data processing code. Refer to \url{README.md} in the repository for
details regarding system requirements and how to run the data processing code. 

\subsection{The raw data: origin, description, and challenges}
\label{sec:raw}

\paragraph{Origin.}
The first raw data files in this repository were obtained by J.~Kalven, an 
independent journalist, who filed Illinois Freedom of Information Act (FOIA) requests with 
the Chicago Police Department regarding complaints filed against officers. 
In Kalven v.~City of Chicago \cite{kalven2014}, an Illinois appellate court issued
a general ruling that documents bearing on allegations of
police abuse are public information. Following 
the decision, the non-profit
Invisible Institute began to collaborate with Kalven 
and the University of Chicago's Mandel Legal Aid
Clinic to follow up on earlier FOIA requests and to file new ones. The data
disclosed in response to these earlier and now ongoing FOIA requests were made available
online as part of the Citizens Police Data Project \cite{cpdp}.
These data form the basis of the cleaned and linked data set provided by the present work.

\begin{table}[h]
	\begin{center}
\caption{Summary of the FOIA requests contained in our repository (blanks are missing entries).}
\label{table:summary}
\begin{tabular}{@{}llllr@{}}
	\toprule
	Request \#&Received&Requested&Description& \# Records\\
\midrule
	\texttt{P0-58155}&2017-04-17& &Officer roster& 32\,446\\
	\texttt{P4-41436}&2018-03-21& &Officer roster& 14\,634\\
	\texttt{16-1105}&2016-03-11&2016-02-10&Unit assignments&114\,630\\
	\texttt{P0-52262}&2016-12-04&2016-09-19&Unit assignments&115\,987\\
	\texttt{P0-46957}&2016-06-29&2016-04-22&Complaints (CPD)&109\,339\\
	\texttt{18-060-425}&2018-08-28&2018-08-20&Complaints (COPA)&182\,337\\
	\texttt{P0-46360}& & &Tactical Response Reports&67\,019\\
	\texttt{P0-46987}&2016-05-13&2016-04-25&Unit names&237\\
	\texttt{P0-61715}& &2017-07-26&Awards&699\,912\\
	\texttt{P5-06887}&2019-10-11&2019-07-19&Awards&60\,556\\
					 &2017-09-27&2017-09-13&Salary&212\,508\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\paragraph{Description.}
The raw data files are contained in the \url{raw/} folder of the
repository. Each subfolder corresponds to a FOIA request, which is
generally identified by a request number. \cref{table:summary} gives
an overview of all the requests that we include in
our repository; this meta-information is also included in the \url{raw/datasets.csv}
file in the repository. The subfolders contain the data provided by the city
in response to their corresponding FOIA requests, which typically comprises multiple
Excel spreadsheets. In addition, when available, the subfolders contain formal correspondence 
regarding the request, which often provides useful contextual information in understanding the data.  

In particular, the raw data files contained in the repository
provide the following information:
\begin{description}
	\item[Officer roster:] a list of all officers (past and present) employed
		by the CPD along with attributes such as year of birth, age, race,
		gender, appointment date, resignation date, etc.
	\item[Unit assignments:] the CPD is organized into over 200 units.
		Each officer can be assigned to one or multiple units and these
		assignments can change over time. The unit assignment datasets contain
		one record for each officer and each unit they were assigned to, including
		the start date and end date of this assignment.
	\item[Complaints:] formal complaints against police officers, filed both by
		citizens and internally within the department. Complaints are
		identified by a complaint number. There is one record for each
		complaint and each officer listed on the complaint, indicating the
		allegation made against them, result of the investigation of the
		allegation (with possible sanction), etc.
	\item[Tactical Response Reports:] these are forms that officers are
		required to file after each incident for which the officer's response
		involved use of force. There is one record for each incident and each
		officer involved in the incident. Each record contains details about
		the incident (such as time and location), the officer involved and the
		subject of the use of force. In case one or multiple weapons were used,
		detailed information about each use is also provided including, for
		firearms, the number of discharges and the object struck at each
		discharge.
	\item[Unit names:] the (human-readable) name of each past and present
		unit in the CPD. These names provide information about the function of
		each unit and also appear occasionally where unit numbers are listed in
		the other data files.
	\item[Awards:] a list of all awards requested for officers in the CPD,
		including award tracking number, reference number, award type, request
		date, requester name, etc.
	\item[Salary:] a list of officers including their salary, position, and pay grade.
\end{description}

\paragraph{Challenges.}
Despite the richness of the information contained in these FOIA data releases,
there is a major obstacle to using them for investigating the activities of the
CPD. In particular, police officers are not uniquely identified across datasets; there is
a priori no reliable way to know whether, for example, an officer listed on
a Complaint is the same individual as an officer with similar attributes listed
on a Tactical Response Report. Therefore, one is forced to link officers
across datasets using a restricted set of attributes, 
which introduces the following challenges:
\begin{itemize}
	\item \emph{Time-varying attributes:} many attributes change over the
		course of an officer's career in the CPD, such as their unit
		assignments, rank, and badge number (referred to as a ``star'' in the data). 
                Perhaps surprisingly, some
		attributes which would usually be considered stable and useful
		identifiers also change over time. For example, surnames change when
		officers marry, and appointment dates change when database entries are
		corrected internally.
	\item \emph{Multiple internal sources:} the salary data comes from
		a different database. In particular, the officers' names were entered
		separately, which makes linking this data to the other datasets
		particularly challenging.\footnote{Is this the only case in which data from different DB? If so, we could move this bullet point lower down as the other challenges seem ``worse''}
	\item \emph{Inconsistent entries:} various choices were made by the CPD to
		decide which officers to include in each dataset.  There are, for
		example, officers missing from the roster or unit assignment data, but
		present in the salary data. Furthermore, the same attribute can appear
		under different names in different datasets and sometimes have
		ambiguous meanings: for example, the salary data contains two different
		attributes for the appointment date. Fields that are available or missing
		per record also vary across databases.
	\item \emph{Duplicate entries:} probably due to internal errors in the CPD
		data infrastructure, some officers are sometimes duplicated in the
		roster and unit assignment data: they appear twice in the same dataset,
		as two different individuals but with the exact same attributes. One of
		the two “copies” of each duplicate officer is inactive and never
		appears in the rest of the data, but introduces ambiguities to uniquely
		identify officers across datasets.
	\item \emph{Systematic errors:} an unusual difficulty arose from the unit
		assignment data, in which a significant fraction of the assignments
		have an end date chronologically preceding the start date. This appears
		to be a systematic error, either in the data entry process or in the
		code which produced the data. A close inspection of the pattern of
		errors revealed that the faulty records cannot be fixed by simply
		swapping the start date with the end date.
\end{itemize}

A major contribution of the present work is to address all the above challenges
by carefully cleaning and linking the original datasets. The output of this
process is a collection of comma-separated values (CSV) files corresponding to
the different entities in the \emph{Description} paragraph above.
Importantly, each officer is uniquely identified by a hexadecimal string across
output files. The
remainder of this section describes the processing steps in detail.

\subsection{Cleaning}

The files initially released by the CPD are for
the most part Excel spreadsheets, with inconsistent formatting and which can
thus be difficult to process programmatically. As an example, the reader is
invited to open the file
\texttt{p046957\_-\_report\_1.1\_-\_all\_complaints\_in\_time\_frame.xls}
available in the folder \texttt{raw/P0-46957/}. As can be seen, each record in
this file is spread over two rows of the spreadsheet, with the field names
repeated at the beginning of the second row for each record.

Consequently, the goal of the cleaning step is to produce uniformly formatted
CSV files, with the minimum requirement that each record be presented on
a single line after this step. The code is contained in the files
\texttt{datasets.py}, \texttt{parse.py}, \texttt{parse\_p046957.py}, and \texttt{parse\_p061715.py} in the
\texttt{src/} folder.  The step can be applied by running \texttt{make prepare}
in the root of the repository, which creates the folder \texttt{tidy/}
containing the cleaned CSV files.

The decisions made at this stage are straightforward and involve no subjective
judgment. They consist of:
\begin{itemize}
	\item Unifying attribute names across datasets, so that the same type of
		data is always identified in the same way (for example,
		\texttt{Appointment Date}, \texttt{Appt Date},
		\texttt{appointment\_date} are all mapped to
		\texttt{appointment\_date}).
	\item Unifying attribute values across datasets. For example, the gender of
		an officer is indicated as a single letter \texttt{M}/\texttt{F} in
		some datasets, and as \texttt{Male}/\texttt{Female} in others. A similar issue
		arises with the race of officers, sometimes given as a three-letter
		code, and sometimes described in full. In such cases we map all
		possible forms of an attribute value to a canonical one. \footnote{Probably for space, can merge these two bullet points as ``Unifying attribute names and values across datasets''.}
	\item Parsing values into the correct data type or format. For example,
		dates and times are formatted differently depending on the dataset, and
		we map everything to the ISO\,8601 format. Integers are also parsed so
		as to remove the various paddings present in the original data.
	\item Concatenating all the files containing a given type of record in each
		data release. Indeed, the CPD's responses to some FOIA requests split
		the records chronologically over multiple Excel spreadsheets (see for
		example \texttt{raw/P0-46957}) or multiple tables within spreadsheets
                (see for example \texttt{raw/salary}). Having a single file for each record
		type instead simplifies later processing steps.
\end{itemize}

Although this initial cleaning is only the first step in the process producing
our final dataset, we structured our processing code in such a way that it is
easy to stop the process at this step and keep the intermediate output in the
\texttt{tidy/} folder. This is because the next steps required making more
subjective judgment calls, e.g., to decide how to clean erroneous records and resolve
ambiguities arising from the merging and linking of datasets. Consequently, it
is possible that some applications will require performing these next steps
differently. In such cases, the files contained in the \texttt{tidy/} folder
should provide a safe intermediate point at which to branch off from our
processing pipeline.

\subsection{Linking and Merging Datasets}\label{sec:linking}
\label{sec:linking}

All the data processing described in this section and the next can be performed
by running \texttt{make} in the root of the repository. This will output the
final version of our dataset as a collection of CSV files in the
\texttt{final/} folder.

\paragraph{Overall description.}
As discussed in \cref{sec:raw}, the main challenge in processing the raw data
is that officers are not uniquely identified across datasets. In other words,
there is no foolproof way to know if two different records from two different
datasets correspond to the same individual. For example, a na\"ive matching
procedure identifying two officers as being the same individual whenever they
have the same name is inadequate: given the size of the CPD roster (over 35\,000
active or retired officers), it is guaranteed to contain many homonymous
individuals. Furthermore, even though the original datasets contain several
identifying attributes (name, birth year, appointment date, race, gender),
 those can change over item as mentioned in \cref{sec:raw}.

At a high level, our procedure \emph{grows} a population of uniquely identified
officers by sequentially examining each FOIA release. Each unique officer in
this population is assigned a unique identification (UID), which is a random hexadecimal string (e.g.\
\texttt{9bc51eef-c37b-4eff-a14d-7e69f56b3d1e}), and to each UID is associated
a list of \emph{officer profiles}. There is one \emph{officer profile} for each
unique officer and each FOIA release in which this officer appeared, listing
the identifying attributes of this officer as they appear in this given data
release. In detail, for each FOIA release:
\begin{enumerate}
	\item We build a list of all the \emph{officer profiles} appearing in this
		release.
	\item For each officer profile, we attempt to \emph{match} it against the
		profiles of the population of unique officers constructed so far from
		previously examined FOIA releases.
		\begin{itemize}
			\item If the match is successful, we have identified a unique officer in
				the population whose profiles unambiguously match with the
				current profile. In this case, we simply attach the current
				profile to this officer and UID, and
				the population does not grow.
			\item If the match is unsuccessful, we add a new officer with a new UID to the population of unique
				officers and attach the current profile to this new officer.
		\end{itemize}
\end{enumerate}

After all FOIA releases have been processed, the population contains the set of
all unique officers appearing in the original data. Each officer is represented
by UID and a collection of profiles, representing the various ways in which
this unique officer appears across different datasets. These profiles can be
found in the file \texttt{final/officer\_profiles.csv}.
At this point the \texttt{final/} folder also contains
one file for each type of record (complaints, tactical response reports, etc).
Within these files, officers are identified solely by their UID and other attributes
are removed; this avoids duplication of
information since these attributes are redundant with those found in
\texttt{final/officer\_profiles.csv}.



Note that this procedure depends on the order in which the FOIA releases are processed,
since each release will be matched against the profiles from all
previously considered releases. We chose to first process the two roster datasets
(\texttt{P0-58155} and \texttt{P4-41436}) since they are most similar and
supposed to contain one record for each officer in the CPD. Next, we process
the two unit assignments datasets (\texttt{16-1105} and \texttt{P0-52262})
since they are also supposed to cover the entire CPD. Finally, we process the
complaints, tactical response reports, awards, and salary data, in this
order.

\paragraph{Iterative pairwise matching.}
It remains to describe the \emph{match} operation which was left unspecified in
step 2.\ of the procedure above. This operation
matches a list of profiles found in the FOIA release being currently processed
against an already existing list of profiles and associated UIDs. We need to strike a balance between:
\begin{itemize}
	\item Being loose enough to avoid type II error (false negatives). If the
		same officer appears with slightly different attributes in two
		different profiles, we do not want the matching method to believe these
		profiles are attached to different officers.
	\item Being strict enough to avoid type I error (false positives). We do
		not want to attach a profile to an officer currently in the population
		if it in fact corresponds to a new officer.
\end{itemize}

We developed an \emph{iterative pairwise matching procedure}\footnote{This
procedure was inspired by a similar one developed by the Invisible Institute.},
that makes iterative passes over the list $L_1$ of profiles to be matched
against the list $L_2$ of already existing profiles. Recall that in our case,
the profiles in $L_2$ are associated with officers in the growing population of
unique officers, and hence they are each associated with a UID. During each
pass:
\begin{enumerate}
	\item A subset $S$ of the profile attributes is selected as the matching
		criterion.
	\item For each profile $p$ in $L_1$:
		\begin{enumerate}
			\item Construct the list $\ell_p$ of profiles in $L_2$ for which
				the attributes in $S$ match with $p$ exactly.
			\item If all the profiles in $\ell_p$ are associated with the same
				UID $u$, this is an unambiguous match and we can safely assign
				the UID $u$ to the profile $p$. We remove $p$ from $L_1$ and
				all the profiles associated with $u$ in $L_2$.
			\item Otherwise, the match is ambiguous and we keep $p$ in
				$L_1$.
		\end{enumerate}
\end{enumerate}
Observe that both $L_1$ and $L_2$ decrease in size as matches are found, so
each pass iterates over a smaller set of profiles than the previous one. When
all passes are done, the remaining profiles in $L_1$ are considered new
unique officers and assigned freshly generated UIDs. Furthermore, by
building at each pass a hash table mapping a subset of attributes to the
list of profiles in $L_2$ sharing these attributes, the construction of
$\ell_p$ in 2.(a) can be performed in constant time. The overall running time of the
  iterative matching procedure is $O\big(P(|L_1|+|L_2|)\big)$ where $P$ is the
  number of passes.\footnote{\textcolor{red}{If we are talking about running time, I think we could also mention that - in practice - this procedure runs in less than a minute (or actually, check how long it takes) on a standard machine?}}

Finally, to fully specify the matching procedure we need to describe how to
choose which subset $S$ of identifying attributes is chosen as the matching
criterion at step 1.\ during each pass. For this, we go from the stricter to
the looser criterion: in the first pass, $S$ contains \emph{all} the attributes
which are present in both $L_1$ and $L_2$, and then attributes are removed from
$S$ one by one in subsequent passes. For example, one can remove the \emph{last
name} attribute in the second pass to match a pair of profiles whose last names
are different but match on all the remaining attributes, thus identifying an
officer whose last name changed between two FOIA releases. The advantage of
going from stricter to looser is twofold:
\begin{itemize}
	\item Starting from the strictest set of attributes identifies the
		\emph{least ambiguous matches}, for which profiles match exactly on
		a large set of attributes and can confidently be considered to describe
		the same individual. This constitutes the vast majority of cases;
		more than 95\% of profiles are usually matched during the first pass.
		Since the next passes iterate only on the remaining profiles, this
		removes the majority of ambiguities that could arise as the
		matching criterion is relaxed.
	\item Since the vast majority of profiles are matched in the first pass,
		it becomes feasible in subsequent passes to visually inspect all
		the matched profiles and assess whether the chosen set of attributes was
		too strict or too lose.
\end{itemize}

We note that there is some amount of subjective judgement involved;
 visual inspection is employed in the second and subsequent passes to decide which sets
attributes are stringent enough as to avoid accidentally matching two different persons. 
This is also how we decide that sufficiently many passes have been
performed and that further relaxing the matching criterion would introduce too
many type I errors. In general, we erred on the side of favoring
type II errors over type I errors when uncertain.

%\textbf{TODO:} explain the few subtleties where we don't use equality to match
%attributes (for example when matching age and birthyear, where the age only
%lets us identify the birthyear with an accuracy of 1 year). Or with stars,
%where we test whether a star number is contained in the subset of known stars
%for this officer.

%\textbf{TODO:} table of officer attributes in each dataset


\subsection{Final cleaning and output}

\input{sections/data-bis.tex}


\paragraph{Final output.}
